{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "5  0.260314 -0.568671  ...   -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5 -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "\n",
       "[6 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_classes = pd.value_counts(data['Class']).sort_index()\n",
    "count_classes\n",
    "#count_classes.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:3: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "      <th>normAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "      <td>1.160686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.073403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10     ...           V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794     ...     -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974     ...     -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643     ...      0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952     ...     -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074     ...     -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  normAmount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053      0    0.244964  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   -0.342475  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0    1.160686  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458      0    0.140534  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153      0   -0.073403  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data['normAmount'] = StandardScaler().fit_transform(data['Amount'].reshape(-1,1))\n",
    "data = data.drop(['Time','Amount'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "984\n"
     ]
    }
   ],
   "source": [
    "X = data.ix[:,data.columns !='Class']\n",
    "y = data.ix[:,data.columns =='Class']\n",
    "\n",
    "number_records_fraud = len(data[data.Class ==1])\n",
    "fraud_indices = np.array( data[ data.Class==1].index)\n",
    "\n",
    "normal_indices = data[data.Class==0].index\n",
    "\n",
    "random_normal_indices = np.random.choice(normal_indices,number_records_fraud,replace = False)\n",
    "random_normal_indices = np.array(random_normal_indices)\n",
    "\n",
    "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
    "under_sample_data = data.iloc[under_sample_indices,:]\n",
    "\n",
    "X_undersample = under_sample_data.ix[:,under_sample_data.columns != 'Class']\n",
    "y_undersample = under_sample_data.ix[:,under_sample_data.columns == 'Class']\n",
    "print(len(under_sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions train dataset:  199364\n",
      "Number transactions test dataset:  85443\n",
      "Total number of transactions:  284807\n",
      "\n",
      "Number transactions train dataset:  688\n",
      "Number transactions test dataset:  296\n",
      "Total number of transactions:  984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state = 0)\n",
    "print(\"Number transactions train dataset: \", len(X_train))\n",
    "print(\"Number transactions test dataset: \", len(X_test))\n",
    "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
    "X_train_undersample,X_test_undersample,y_train_undersample,y_test_undersample = train_test_split(X_undersample,y_undersample,test_size=0.3,random_state = 0)\n",
    "print(\"\")\n",
    "print(\"Number transactions train dataset: \", len(X_train_undersample))\n",
    "print(\"Number transactions test dataset: \", len(X_test_undersample))\n",
    "print(\"Total number of transactions: \", len(X_train_undersample)+len(X_test_undersample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "C parameter:  0.01\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.931506849315\n",
      "Iteration  2 : recall score =  0.917808219178\n",
      "Iteration  3 : recall score =  1.0\n",
      "Iteration  4 : recall score =  0.972972972973\n",
      "Iteration  5 : recall score =  0.954545454545\n",
      "\n",
      "Mean recall score  0.955366699202\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  0.1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.835616438356\n",
      "Iteration  2 : recall score =  0.86301369863\n",
      "Iteration  3 : recall score =  0.915254237288\n",
      "Iteration  4 : recall score =  0.918918918919\n",
      "Iteration  5 : recall score =  0.893939393939\n",
      "\n",
      "Mean recall score  0.885348537427\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  1\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.849315068493\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.966101694915\n",
      "Iteration  4 : recall score =  0.932432432432\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.909470212767\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  10\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.966101694915\n",
      "Iteration  4 : recall score =  0.932432432432\n",
      "Iteration  5 : recall score =  0.909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean recall score  0.912209938795\n",
      "\n",
      "-------------------------------------------\n",
      "C parameter:  100\n",
      "-------------------------------------------\n",
      "\n",
      "Iteration  1 : recall score =  0.86301369863\n",
      "Iteration  2 : recall score =  0.890410958904\n",
      "Iteration  3 : recall score =  0.966101694915\n",
      "Iteration  4 : recall score =  0.932432432432\n",
      "Iteration  5 : recall score =  0.909090909091\n",
      "\n",
      "Mean recall score  0.912209938795\n",
      "\n",
      "*********************************************************************************\n",
      "Best model to choose from cross validation is with C parameter =  0.01\n",
      "*********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold,cross_val_score\n",
    "from sklearn.metrics import confusion_matrix,recall_score,classification_report\n",
    "\n",
    "def printing_Kfold_scores(x_train_data,y_train_data):\n",
    "    fold = KFold(len(y_train_data),5,shuffle=False)\n",
    "    \n",
    "    c_param_range = [0.01,0.1,1,10,100]\n",
    "    results_table = pd.DataFrame(index = range(len(c_param_range),2),columns = ['C_parameter','Mean recall score'])\n",
    "    results_table['C_parameter'] = c_param_range\n",
    "    \n",
    "    j = 0\n",
    "    for c_param in c_param_range:\n",
    "        print('-------------------------------------------')\n",
    "        print('C parameter: ', c_param)\n",
    "        print('-------------------------------------------')\n",
    "        print('')\n",
    "        \n",
    "        recall_accs = []\n",
    "        for iteration,indices in enumerate(fold,start=1):\n",
    "            lr = LogisticRegression(C=c_param,penalty='l1')\n",
    "            lr.fit(x_train_data.iloc[indices[0],:],y_train_data.iloc[indices[0],:])\n",
    "            y_pred_undersample = lr.predict(x_train_data.iloc[indices[1],:])\n",
    "            \n",
    "            recall_acc = recall_score(y_train_data.iloc[indices[1],:],y_pred_undersample)\n",
    "            recall_accs.append(recall_acc)\n",
    "            print('Iteration ', iteration,': recall score = ', recall_acc)\n",
    "        results_table.ix[j,'Mean recall score'] = np.mean(recall_accs)\n",
    "        j += 1\n",
    "        print('')\n",
    "        print('Mean recall score ', np.mean(recall_accs))\n",
    "        print('')\n",
    "        \n",
    "    best_c = results_table.loc[results_table['Mean recall score'].idxmax()]['C_parameter']\n",
    "    \n",
    "    # Finally, we can check which C parameter is the best amongst the chosen.\n",
    "    print('*********************************************************************************')\n",
    "    print('Best model to choose from cross validation is with C parameter = ', best_c)\n",
    "    print('*********************************************************************************')\n",
    "    \n",
    "    return best_c\n",
    "best_c = printing_Kfold_scores(X_train_undersample,y_train_undersample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks)\n",
    "    plt.yticks(tick_marks)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall metric in the testing dataset:  0.931972789116\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAEmCAYAAACnN7/iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng8XMknOwmFlyDhYzS87BYmbJ/T8kLvd7eEmCxwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb9955d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import itertools\n",
    "lr = LogisticRegression(C = best_c, penalty = 'l1')\n",
    "lr.fit(X_train_undersample,y_train_undersample.values.ravel())\n",
    "y_pred_undersample = lr.predict(X_test_undersample.values)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test_undersample,y_pred_undersample)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(\"Recall metric in the testing dataset: \", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
